{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8f17ceb",
   "metadata": {},
   "source": [
    "# Image Week - Day 1 - Exercice 2 - Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda65232",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/leclairearthur/imageweek/blob/main/exo2.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba79f28c",
   "metadata": {},
   "source": [
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d069f799",
   "metadata": {},
   "source": [
    "In this practical session, you have to complete the code regions marked ``### ... ###``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68483d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea05b0",
   "metadata": {},
   "source": [
    "We will search for the minimum of the function $f : \\mathbb{R}^2 \\to \\mathbb{R}$ displayed in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb317301",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr,nc = 256,256\n",
    "a = 3\n",
    "extent = ((-a-0.5/nc, a-0.5/nc, -a-0.5/nr, a-0.5/nr))\n",
    "xs = np.linspace(-a, a, nr)\n",
    "ys = np.linspace(-a, a, nc)\n",
    "xm, ym = np.meshgrid(xs, ys, indexing='ij')\n",
    "xm = xm.T\n",
    "ym = ym.T\n",
    "\n",
    "y = xm**2 + ym**2 - np.sin(xm*2)*ym\n",
    "# other choices for fun:\n",
    "#   y = np.sqrt(1+xm**2 + ym**2 - np.sin(xm*2)*ym)\n",
    "#   y = 2*ym**2-np.cos(xm*3)*ym + 2*xm**2 \n",
    "\n",
    "fig = plt.figure(dpi=150)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(y,cmap = 'gray', extent=extent)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8d559c",
   "metadata": {},
   "source": [
    "**QUESTION :** Define the function f (taking as input a tensor of shape (2)), and compute its gradient with Pytorch. Check the obtained values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    ### ... ###\n",
    "\n",
    "# compute the gradient of f at point (1,0)\n",
    "### ... ###\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf5c153",
   "metadata": {},
   "source": [
    "**QUESTION :** Implement the gradient descent (with fixed step size $\\tau$). At each step, you compute the gradient by automatic differentiation ``backward()``.\n",
    "\n",
    "Check the convergence result by plotting the values of $f$ along the iterates $(x_n)$.\n",
    "\n",
    "If you are able to find the true solution $x_*$, you can also plot the error norm $\\|x_n - x_*\\|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5de18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x0 = np.array([-1.8,2])   # initial point\n",
    "\n",
    "tau = .1\n",
    "N = 1000\n",
    "xd = np.zeros((N,2))\n",
    "\n",
    "fxlist = []\n",
    "\n",
    "x = ### ... ###\n",
    "for n in range(N):\n",
    "    \n",
    "    ### ... ###\n",
    "    \n",
    "    xd[n,:] = ### ... ###   # store current x value \n",
    "    fxlist.append(fx.item())\n",
    "\n",
    "fig = plt.figure(dpi=150)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(y,cmap = 'gray', extent=extent)\n",
    "plt.scatter(x0[0], x0[1],c='red',alpha=.5)\n",
    "plt.scatter(xd[:, 0], xd[:,1],c='deepskyblue',alpha=.5)\n",
    "plt.show()\n",
    "\n",
    "### ... ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe905499",
   "metadata": {},
   "source": [
    "**QUESTION:** Compare by doing gradient descent with the Pytorch routine ``torch.optim.SGD`` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6209363",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x0, requires_grad=True)\n",
    "optim = torch.optim.SGD([x], lr=tau)\n",
    "losslist = []\n",
    "for it in range(N):\n",
    "    loss = f(x)\n",
    "    losslist.append(loss.item())\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f75df1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    print(fxlist[i], losslist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03e279a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
